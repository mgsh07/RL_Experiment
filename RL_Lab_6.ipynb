{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCvZ5XjKuESLCFZLCLy8qn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeelaNandhaKishore1511/RL-Lab-Sem-5/blob/main/RL_Lab_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym,gym_bandits\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "J-G7YixJLPdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env=gym.make(\"MultiarmedBandits-v0\")\n",
        "data = pd.read_csv('Ads_CTR_Optimisation.csv')"
      ],
      "metadata": {
        "id": "q207QeheL58x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_reward = data.shape[0]\n",
        "num_ads = data.shape[1]\n",
        "selected_ads = []\n",
        "\n",
        "ad_counts = np.zeros(num_ads)\n",
        "ad_rewards = np.zeros(num_ads)\n",
        "epsilon = 0.1\n",
        "total_rounds = data.shape[0]\n",
        "for round_num in range(total_rounds):\n",
        "    if random.random() < epsilon:\n",
        "        chosen_ad = random.randrange(num_ads)\n",
        "    else:\n",
        "        average_rewards = np.divide(ad_rewards, ad_counts, out=np.zeros_like(ad_rewards, dtype=float), where=ad_counts != 0)\n",
        "        chosen_ad = np.argmax(average_rewards)\n",
        "\n",
        "    selected_ads.append(chosen_ad)\n",
        "\n",
        "    reward = data.values[round_num, chosen_ad]\n",
        "\n",
        "    ad_counts[chosen_ad] += 1\n",
        "    ad_rewards[chosen_ad] += reward\n",
        "\n",
        "\n",
        "best_ad = np.argmax(ad_rewards) + 1\n",
        "print(f\"The best performing ad is Ad {best_ad}\")\n",
        "\n",
        "plt.hist(selected_ads, bins=range(num_ads + 1), align='left', rwidth=0.8)\n",
        "plt.xlabel(\"Ad Number\")\n",
        "plt.ylabel(\"Number of Times Selected\")\n",
        "plt.title(\"Distribution of Selected Ads (Epsilon-Greedy)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "7iG2EEG8LPbR",
        "outputId": "31d4e0e4-be22-4202-d30e-6bd0670c509f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best performing ad is Ad 5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Distribution of Selected Ads (Epsilon-Greedy)')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "envs = gym.envs.registry\n",
        "total_envs = len(envs)\n",
        "print(f\"Total number of environments: {total_envs}\")\n",
        "env_names = sorted([env_spec.id for env_spec in envs.values()]) # Iterate through the values of the registry dictionary\n",
        "for i in env_names:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGHZOOe8S61v",
        "outputId": "dc28e9fa-6b54-4ecc-c739-1ae4c3ea30ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of environments: 45\n",
            "Acrobot-v1\n",
            "Ant-v2\n",
            "Ant-v3\n",
            "Ant-v4\n",
            "BipedalWalker-v3\n",
            "BipedalWalkerHardcore-v3\n",
            "Blackjack-v1\n",
            "CarRacing-v2\n",
            "CartPole-v0\n",
            "CartPole-v1\n",
            "CliffWalking-v0\n",
            "FrozenLake-v1\n",
            "FrozenLake8x8-v1\n",
            "HalfCheetah-v2\n",
            "HalfCheetah-v3\n",
            "HalfCheetah-v4\n",
            "Hopper-v2\n",
            "Hopper-v3\n",
            "Hopper-v4\n",
            "Humanoid-v2\n",
            "Humanoid-v3\n",
            "Humanoid-v4\n",
            "HumanoidStandup-v2\n",
            "HumanoidStandup-v4\n",
            "InvertedDoublePendulum-v2\n",
            "InvertedDoublePendulum-v4\n",
            "InvertedPendulum-v2\n",
            "InvertedPendulum-v4\n",
            "LunarLander-v2\n",
            "LunarLanderContinuous-v2\n",
            "MountainCar-v0\n",
            "MountainCarContinuous-v0\n",
            "MultiarmedBandits-v0\n",
            "Pendulum-v1\n",
            "Pusher-v2\n",
            "Pusher-v4\n",
            "Reacher-v2\n",
            "Reacher-v4\n",
            "Swimmer-v2\n",
            "Swimmer-v3\n",
            "Swimmer-v4\n",
            "Taxi-v3\n",
            "Walker2d-v2\n",
            "Walker2d-v3\n",
            "Walker2d-v4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CartPole Environment\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "state, info = env.reset() # Unpack state and info\n",
        "\n",
        "print(\"Action Space:\", env.action_space)\n",
        "print(\"Observation Space:\", env.observation_space)\n",
        "\n",
        "def describe_state(state):\n",
        "  # Add a check here as well\n",
        "  if not isinstance(state, np.ndarray) or state.shape != (4,):\n",
        "      print(f\"Unexpected state format in describe_state: Type - {type(state)}, Shape - {getattr(state, 'shape', 'N/A')}\")\n",
        "      return # Exit the function if state is not the expected format\n",
        "\n",
        "  cart_position, cart_velocity, pole_angle, pole_velocity = state\n",
        "  print(f\"Cart Position: {cart_position}\")\n",
        "  print(f\"Cart Velocity: {cart_velocity}\")\n",
        "  print(f\"Pole Angle: {pole_angle}\")\n",
        "  print(f\"Pole Velocity: {pole_velocity}\")\n",
        "\n",
        "print(\"Initial State:\")\n",
        "describe_state(state)\n",
        "\n",
        "actions = {0: \"Move Left\", 1: \"Move Right\"}\n",
        "for action in actions:\n",
        "    print(f\"Action {action}: {actions[action]}\")\n",
        "\n",
        "num_steps = 5\n",
        "print(\"\\nSimulating a few steps:\")\n",
        "for step in range(num_steps):\n",
        "    action = env.action_space.sample()  # Sample an action\n",
        "    next_state, reward, done, truncated, info = env.step(action) # Take the step with the sampled action\n",
        "\n",
        "    print(f\"\\nStep {step + 1}:\")\n",
        "    print(f\"Action taken: {actions[action]}\") # Print the actual action taken\n",
        "    print(\"Next State:\")\n",
        "    # Add print statements to diagnose next_state\n",
        "    print(f\"Type of next_state: {type(next_state)}\")\n",
        "    try:\n",
        "        print(f\"Shape of next_state: {next_state.shape}\")\n",
        "    except AttributeError:\n",
        "        print(\"next_state does not have a shape attribute\")\n",
        "    print(f\"Value of next_state: {next_state}\")\n",
        "\n",
        "\n",
        "    describe_state(next_state) # Pass the observation (next_state) to describe_state\n",
        "    print(f\"Reward: {reward}\")\n",
        "    print(f\"Done: {done}\")\n",
        "    # print(f\"Truncated: {truncated}\") # Optional: Print truncated\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "917xxlskS6s6",
        "outputId": "98239260-3fd0-4bdd-c7ff-441df6d031b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(2)\n",
            "Observation Space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
            "Initial State:\n",
            "Cart Position: 0.004315102007240057\n",
            "Cart Velocity: -0.020276103168725967\n",
            "Pole Angle: -0.02446138486266136\n",
            "Pole Velocity: 0.01894913613796234\n",
            "Action 0: Move Left\n",
            "Action 1: Move Right\n",
            "\n",
            "Simulating a few steps:\n",
            "\n",
            "Step 1:\n",
            "Action taken: Move Left\n",
            "Next State:\n",
            "Type of next_state: <class 'numpy.ndarray'>\n",
            "Shape of next_state: (4,)\n",
            "Value of next_state: [ 0.00390958 -0.21503887 -0.0240824   0.30381495]\n",
            "Cart Position: 0.003909579943865538\n",
            "Cart Velocity: -0.21503886580467224\n",
            "Pole Angle: -0.024082401767373085\n",
            "Pole Velocity: 0.30381494760513306\n",
            "Reward: 1.0\n",
            "Done: False\n",
            "\n",
            "Step 2:\n",
            "Action taken: Move Left\n",
            "Next State:\n",
            "Type of next_state: <class 'numpy.ndarray'>\n",
            "Shape of next_state: (4,)\n",
            "Value of next_state: [-3.9119757e-04 -4.0980947e-01 -1.8006103e-02  5.8880663e-01]\n",
            "Cart Position: -0.0003911975654773414\n",
            "Cart Velocity: -0.4098094701766968\n",
            "Pole Angle: -0.018006103113293648\n",
            "Pole Velocity: 0.5888066291809082\n",
            "Reward: 1.0\n",
            "Done: False\n",
            "\n",
            "Step 3:\n",
            "Action taken: Move Right\n",
            "Next State:\n",
            "Type of next_state: <class 'numpy.ndarray'>\n",
            "Shape of next_state: (4,)\n",
            "Value of next_state: [-0.00858739 -0.21444008 -0.00622997  0.2905065 ]\n",
            "Cart Position: -0.008587387390434742\n",
            "Cart Velocity: -0.21444007754325867\n",
            "Pole Angle: -0.006229971069842577\n",
            "Pole Velocity: 0.290506511926651\n",
            "Reward: 1.0\n",
            "Done: False\n",
            "\n",
            "Step 4:\n",
            "Action taken: Move Left\n",
            "Next State:\n",
            "Type of next_state: <class 'numpy.ndarray'>\n",
            "Shape of next_state: (4,)\n",
            "Value of next_state: [-1.2876188e-02 -4.0947264e-01 -4.1984103e-04  5.8121806e-01]\n",
            "Cart Position: -0.01287618838250637\n",
            "Cart Velocity: -0.40947264432907104\n",
            "Pole Angle: -0.0004198410315439105\n",
            "Pole Velocity: 0.5812180638313293\n",
            "Reward: 1.0\n",
            "Done: False\n",
            "\n",
            "Step 5:\n",
            "Action taken: Move Left\n",
            "Next State:\n",
            "Type of next_state: <class 'numpy.ndarray'>\n",
            "Shape of next_state: (4,)\n",
            "Value of next_state: [-0.02106564 -0.6045887   0.01120452  0.8737687 ]\n",
            "Cart Position: -0.021065641194581985\n",
            "Cart Velocity: -0.6045886874198914\n",
            "Pole Angle: 0.011204520240426064\n",
            "Pole Velocity: 0.87376868724823\n",
            "Reward: 1.0\n",
            "Done: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "env = gym.make(\"FrozenLake-v1\", is_slippery=False)\n",
        "observation, info = env.reset()\n",
        "\n",
        "print(\"Action Space:\", env.action_space)\n",
        "print(\"Observation Space:\", env.observation_space)\n",
        "\n",
        "def describe_state(observation, map_size=4):\n",
        "    if not isinstance(observation, int):\n",
        "        print(f\"Unexpected observation format in describe_state: Type - {type(observation)}, Value - {observation}\")\n",
        "        return\n",
        "\n",
        "    row = observation // map_size\n",
        "    col = observation % map_size\n",
        "\n",
        "    grid = [\n",
        "        \"SFFF\",\n",
        "        \"FHFH\",\n",
        "        \"FFFH\",\n",
        "        \"HFFG\"\n",
        "    ]\n",
        "\n",
        "    current_cell_type = grid[row][col]\n",
        "\n",
        "    print(f\"Current Position (Observation): {observation}\")\n",
        "    print(f\"Current Row: {row}, Current Column: {col}\")\n",
        "    print(f\"Current Cell Type: {current_cell_type}\")\n",
        "    print(f\"Grid Size: {map_size}x{map_size}\")\n",
        "\n",
        "\n",
        "print(\"\\nInitial State:\")\n",
        "describe_state(observation)\n",
        "\n",
        "actions = {0: \"Left\", 1: \"Down\", 2: \"Right\", 3: \"Up\"}\n",
        "for action_id in actions:\n",
        "    print(f\"Action {action_id}: {actions[action_id]}\")\n",
        "\n",
        "\n",
        "num_steps = 5\n",
        "print(\"\\nSimulating a few steps:\")\n",
        "for step in range(num_steps):\n",
        "    action = env.action_space.sample()\n",
        "    next_observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "    print(f\"\\nStep {step + 1}:\")\n",
        "    print(f\"Action taken: {actions[action]}\")\n",
        "    print(\"Next State (Observation):\")\n",
        "    print(f\"Type of next_observation: {type(next_observation)}\")\n",
        "    print(f\"Value of next_observation: {next_observation}\")\n",
        "\n",
        "\n",
        "    describe_state(next_observation)\n",
        "    print(f\"Reward: {reward}\")\n",
        "    print(f\"Terminated: {terminated}\")\n",
        "    print(f\"Truncated: {truncated}\")\n",
        "\n",
        "    if terminated or truncated:\n",
        "        print(\"Episode ended.\")\n",
        "        observation, info = env.reset()  # Reset for a new episode if done or truncated\n",
        "        print(\"\\nNew Episode Started. Initial State:\")\n",
        "        describe_state(observation)\n",
        "\n",
        "\n",
        "env.close()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC_ENhebaeZP",
        "outputId": "31b5c9a9-425b-4bfe-ba80-6b38e9ddc1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(4)\n",
            "Observation Space: Discrete(16)\n",
            "\n",
            "Initial State:\n",
            "Current Position (Observation): 0\n",
            "Current Row: 0, Current Column: 0\n",
            "Current Cell Type: S\n",
            "Grid Size: 4x4\n",
            "Action 0: Left\n",
            "Action 1: Down\n",
            "Action 2: Right\n",
            "Action 3: Up\n",
            "\n",
            "Simulating a few steps:\n",
            "\n",
            "Step 1:\n",
            "Action taken: Left\n",
            "Next State (Observation):\n",
            "Type of next_observation: <class 'int'>\n",
            "Value of next_observation: 0\n",
            "Current Position (Observation): 0\n",
            "Current Row: 0, Current Column: 0\n",
            "Current Cell Type: S\n",
            "Grid Size: 4x4\n",
            "Reward: 0.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 2:\n",
            "Action taken: Right\n",
            "Next State (Observation):\n",
            "Type of next_observation: <class 'int'>\n",
            "Value of next_observation: 1\n",
            "Current Position (Observation): 1\n",
            "Current Row: 0, Current Column: 1\n",
            "Current Cell Type: F\n",
            "Grid Size: 4x4\n",
            "Reward: 0.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 3:\n",
            "Action taken: Up\n",
            "Next State (Observation):\n",
            "Type of next_observation: <class 'int'>\n",
            "Value of next_observation: 1\n",
            "Current Position (Observation): 1\n",
            "Current Row: 0, Current Column: 1\n",
            "Current Cell Type: F\n",
            "Grid Size: 4x4\n",
            "Reward: 0.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 4:\n",
            "Action taken: Left\n",
            "Next State (Observation):\n",
            "Type of next_observation: <class 'int'>\n",
            "Value of next_observation: 0\n",
            "Current Position (Observation): 0\n",
            "Current Row: 0, Current Column: 0\n",
            "Current Cell Type: S\n",
            "Grid Size: 4x4\n",
            "Reward: 0.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 5:\n",
            "Action taken: Up\n",
            "Next State (Observation):\n",
            "Type of next_observation: <class 'int'>\n",
            "Value of next_observation: 0\n",
            "Current Position (Observation): 0\n",
            "Current Row: 0, Current Column: 0\n",
            "Current Cell Type: S\n",
            "Grid Size: 4x4\n",
            "Reward: 0.0\n",
            "Terminated: False\n",
            "Truncated: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "# Create the Mountain Car environment\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "\n",
        "# Reset the environment and get the initial observation (state) and info\n",
        "# The observation for MountainCar-v0 is a NumPy array with two elements: [position, velocity]\n",
        "observation, info = env.reset()\n",
        "\n",
        "print(\"Action Space:\", env.action_space)  # Discrete(3): 0=Left, 1=Nothing, 2=Right\n",
        "print(\"Observation Space:\", env.observation_space) # Box(2,) - Continuous space for position and velocity\n",
        "\n",
        "\n",
        "def describe_state(observation):\n",
        "    \"\"\"\n",
        "    Describes the Mountain Car state (observation).\n",
        "    The observation is a NumPy array [position, velocity].\n",
        "    \"\"\"\n",
        "    # Check for the expected format: a NumPy array with two elements\n",
        "    if not isinstance(observation, np.ndarray) or observation.shape != (2,):\n",
        "        print(f\"Unexpected observation format in describe_state: Type - {type(observation)}, Shape - {getattr(observation, 'shape', 'N/A')}\")\n",
        "        return\n",
        "\n",
        "    position, velocity = observation\n",
        "    print(f\"Car Position: {position:.4f}\")  # Format to 4 decimal places for readability\n",
        "    print(f\"Car Velocity: {velocity:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nInitial State:\")\n",
        "describe_state(observation)\n",
        "\n",
        "# Define actions for Mountain Car\n",
        "actions = {0: \"Accelerate Left\", 1: \"Do Nothing\", 2: \"Accelerate Right\"}\n",
        "for action_id in actions:\n",
        "    print(f\"Action {action_id}: {actions[action_id]}\")\n",
        "\n",
        "\n",
        "num_steps = 10  # Simulate a few steps\n",
        "print(\"\\nSimulating a few steps:\")\n",
        "for step in range(num_steps):\n",
        "    action = env.action_space.sample()  # Sample a random action (0-2)\n",
        "\n",
        "    # Take a step in the environment\n",
        "    next_observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "    print(f\"\\nStep {step + 1}:\")\n",
        "    print(f\"Action taken: {actions[action]}\")\n",
        "    print(\"Next State (Observation):\")\n",
        "    describe_state(next_observation)\n",
        "    print(f\"Reward: {reward}\")\n",
        "    print(f\"Terminated: {terminated}\")\n",
        "    print(f\"Truncated: {truncated}\")\n",
        "\n",
        "    if terminated or truncated:\n",
        "        print(\"Episode ended.\")\n",
        "        observation, info = env.reset()  # Reset for a new episode if done or truncated\n",
        "        print(\"\\nNew Episode Started. Initial State:\")\n",
        "        describe_state(observation)\n",
        "\n",
        "\n",
        "env.close()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LhnxY8cbJfA",
        "outputId": "951be22b-262c-43a7-94de-cf91bddbad95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(3)\n",
            "Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
            "\n",
            "Initial State:\n",
            "Car Position: -0.4060\n",
            "Car Velocity: 0.0000\n",
            "Action 0: Accelerate Left\n",
            "Action 1: Do Nothing\n",
            "Action 2: Accelerate Right\n",
            "\n",
            "Simulating a few steps:\n",
            "\n",
            "Step 1:\n",
            "Action taken: Accelerate Right\n",
            "Next State (Observation):\n",
            "Car Position: -0.4059\n",
            "Car Velocity: 0.0001\n",
            "Reward: -1.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 2:\n",
            "Action taken: Do Nothing\n",
            "Next State (Observation):\n",
            "Car Position: -0.4066\n",
            "Car Velocity: -0.0007\n",
            "Reward: -1.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 3:\n",
            "Action taken: Accelerate Right\n",
            "Next State (Observation):\n",
            "Car Position: -0.4072\n",
            "Car Velocity: -0.0006\n",
            "Reward: -1.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 4:\n",
            "Action taken: Accelerate Right\n",
            "Next State (Observation):\n",
            "Car Position: -0.4076\n",
            "Car Velocity: -0.0004\n",
            "Reward: -1.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 5:\n",
            "Action taken: Accelerate Left\n",
            "Next State (Observation):\n",
            "Car Position: -0.4099\n",
            "Car Velocity: -0.0023\n",
            "Reward: -1.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 6:\n",
            "Action taken: Do Nothing\n",
            "Next State (Observation):\n",
            "Car Position: -0.4130\n",
            "Car Velocity: -0.0031\n",
            "Reward: -1.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 7:\n",
            "Action taken: Accelerate Left\n",
            "Next State (Observation):\n",
            "Car Position: -0.4180\n",
            "Car Velocity: -0.0049\n",
            "Reward: -1.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 8:\n",
            "Action taken: Accelerate Right\n",
            "Next State (Observation):\n",
            "Car Position: -0.4227\n",
            "Car Velocity: -0.0047\n",
            "Reward: -1.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 9:\n",
            "Action taken: Accelerate Right\n",
            "Next State (Observation):\n",
            "Car Position: -0.4272\n",
            "Car Velocity: -0.0045\n",
            "Reward: -1.0\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 10:\n",
            "Action taken: Accelerate Left\n",
            "Next State (Observation):\n",
            "Car Position: -0.4334\n",
            "Car Velocity: -0.0062\n",
            "Reward: -1.0\n",
            "Terminated: False\n",
            "Truncated: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "# CreateCreate the Blackjack environment\n",
        "# You can set 'natural' to True for an additional reward for a natural blackjack.\n",
        "# 'sab' (Simplified American Blackjack) uses different rules.\n",
        "env = gym.make(\"Blackjack-v1\", natural=True, sab=False)\n",
        "\n",
        "# Reset the environment to get the initial observation and info\n",
        "observation, info = env.reset()\n",
        "\n",
        "print(\"Action Space:\", env.action_space)  # Discrete(2): 0=Stick, 1=Hit\n",
        "print(\"Observation Space:\", env.observation_space) # Tuple(Discrete(32), Discrete(11), Discrete(2))\n",
        "\n",
        "\n",
        "def describe_state(observation):\n",
        "    \"\"\"\n",
        "    Describes the Blackjack state (observation).\n",
        "    The observation is a 3-tuple: (player_current_sum, dealer_showing_card, usable_ace)\n",
        "    \"\"\"\n",
        "    # Verify the observation format\n",
        "    if not isinstance(observation, tuple) or len(observation) != 3:\n",
        "        print(f\"Unexpected observation format in describe_state: Type - {type(observation)}, Value - {observation}\")\n",
        "        return\n",
        "\n",
        "    player_sum, dealer_card, usable_ace = observation\n",
        "    print(f\"Player's Current Sum: {player_sum}\")\n",
        "    print(f\"Dealer's Showing Card: {dealer_card} (1=Ace, 10=Face Cards)\")\n",
        "    print(f\"Usable Ace: {'Yes' if usable_ace else 'No'}\") # 0 or 1 for no/yes\n",
        "\n",
        "print(\"\\nInitial State:\")\n",
        "describe_state(observation)\n",
        "\n",
        "# Define actions for Blackjack\n",
        "actions = {0: \"Stick (Take no more cards)\", 1: \"Hit (Take another card)\"}\n",
        "for action_id in actions:\n",
        "    print(f\"Action {action_id}: {actions[action_id]}\")\n",
        "\n",
        "\n",
        "num_steps = 5  # Simulate a few steps\n",
        "print(\"\\nSimulating a few steps (until episode ends):\")\n",
        "for step in range(num_steps):\n",
        "    action = env.action_space.sample()  # Sample a random action (0 or 1)\n",
        "\n",
        "    # Take a step in the environment\n",
        "    # next_observation is the new game state\n",
        "    # reward is +1 for win, 0 for draw, -1 for loss (or +1.5 for natural blackjack win)\n",
        "    # terminated is True if the game is over (player busts or sticks)\n",
        "    # truncated is False for this environment (no time limits)\n",
        "    next_observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "    print(f\"\\nStep {step + 1}:\")\n",
        "    print(f\"Action taken: {actions[action]}\")\n",
        "    print(\"Next State (Observation):\")\n",
        "    describe_state(next_observation)\n",
        "    print(f\"Reward: {reward}\")\n",
        "    print(f\"Terminated: {terminated}\") # Indicates if the game has ended\n",
        "    # print(f\"Truncated: {truncated}\") # Blackjack environment does not use truncation\n",
        "\n",
        "    if terminated: # If the episode is over (game ended)\n",
        "        print(\"Game Over. Starting a new game.\")\n",
        "        observation, info = env.reset()  # Reset for a new game\n",
        "        print(\"\\nNew Game Started. Initial State:\")\n",
        "        describe_state(observation)\n",
        "\n",
        "\n",
        "env.close()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S5qxDBBbYb-",
        "outputId": "7b832e8c-2d7a-4bd7-e9a1-09fd0cb6e40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(2)\n",
            "Observation Space: Tuple(Discrete(32), Discrete(11), Discrete(2))\n",
            "\n",
            "Initial State:\n",
            "Player's Current Sum: 16\n",
            "Dealer's Showing Card: 5 (1=Ace, 10=Face Cards)\n",
            "Usable Ace: No\n",
            "Action 0: Stick (Take no more cards)\n",
            "Action 1: Hit (Take another card)\n",
            "\n",
            "Simulating a few steps (until episode ends):\n",
            "\n",
            "Step 1:\n",
            "Action taken: Stick (Take no more cards)\n",
            "Next State (Observation):\n",
            "Player's Current Sum: 16\n",
            "Dealer's Showing Card: 5 (1=Ace, 10=Face Cards)\n",
            "Usable Ace: No\n",
            "Reward: 1.0\n",
            "Terminated: True\n",
            "Game Over. Starting a new game.\n",
            "\n",
            "New Game Started. Initial State:\n",
            "Player's Current Sum: 12\n",
            "Dealer's Showing Card: 1 (1=Ace, 10=Face Cards)\n",
            "Usable Ace: Yes\n",
            "\n",
            "Step 2:\n",
            "Action taken: Hit (Take another card)\n",
            "Next State (Observation):\n",
            "Player's Current Sum: 19\n",
            "Dealer's Showing Card: 1 (1=Ace, 10=Face Cards)\n",
            "Usable Ace: Yes\n",
            "Reward: 0.0\n",
            "Terminated: False\n",
            "\n",
            "Step 3:\n",
            "Action taken: Hit (Take another card)\n",
            "Next State (Observation):\n",
            "Player's Current Sum: 16\n",
            "Dealer's Showing Card: 1 (1=Ace, 10=Face Cards)\n",
            "Usable Ace: No\n",
            "Reward: 0.0\n",
            "Terminated: False\n",
            "\n",
            "Step 4:\n",
            "Action taken: Stick (Take no more cards)\n",
            "Next State (Observation):\n",
            "Player's Current Sum: 16\n",
            "Dealer's Showing Card: 1 (1=Ace, 10=Face Cards)\n",
            "Usable Ace: No\n",
            "Reward: -1.0\n",
            "Terminated: True\n",
            "Game Over. Starting a new game.\n",
            "\n",
            "New Game Started. Initial State:\n",
            "Player's Current Sum: 12\n",
            "Dealer's Showing Card: 2 (1=Ace, 10=Face Cards)\n",
            "Usable Ace: No\n",
            "\n",
            "Step 5:\n",
            "Action taken: Stick (Take no more cards)\n",
            "Next State (Observation):\n",
            "Player's Current Sum: 12\n",
            "Dealer's Showing Card: 2 (1=Ace, 10=Face Cards)\n",
            "Usable Ace: No\n",
            "Reward: -1.0\n",
            "Terminated: True\n",
            "Game Over. Starting a new game.\n",
            "\n",
            "New Game Started. Initial State:\n",
            "Player's Current Sum: 16\n",
            "Dealer's Showing Card: 10 (1=Ace, 10=Face Cards)\n",
            "Usable Ace: No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "# Create the Taxi environment\n",
        "env = gym.make(\"Taxi-v3\")\n",
        "\n",
        "# Reset the environment and get the initial observation (state) and info\n",
        "observation, info = env.reset()\n",
        "\n",
        "print(\"Action Space:\", env.action_space)  # Discrete(6) - for 6 actions\n",
        "print(\"Observation Space:\", env.observation_space) # Discrete(500) - for 500 possible states\n",
        "\n",
        "\n",
        "def describe_state(observation):\n",
        "    \"\"\"\n",
        "    Decodes the Taxi state (observation) into its components and describes it.\n",
        "    The observation is a single integer that encodes (taxi_row, taxi_col, passenger_location, destination).\n",
        "    \"\"\"\n",
        "    # Access the unwrapped environment to use the decode method\n",
        "    taxi_row, taxi_col, passenger_location, destination = env.unwrapped.decode(observation)\n",
        "\n",
        "    passenger_locations = {\n",
        "        0: \"Red (R)\",\n",
        "        1: \"Green (G)\",\n",
        "        2: \"Yellow (Y)\",\n",
        "        3: \"Blue (B)\",\n",
        "        4: \"in Taxi\"\n",
        "    }\n",
        "\n",
        "    destination_locations = {\n",
        "        0: \"Red (R)\",\n",
        "        1: \"Green (G)\",\n",
        "        2: \"Yellow (Y)\",\n",
        "        3: \"Blue (B)\"\n",
        "    }\n",
        "\n",
        "    print(f\"Observation (Encoded State): {observation}\")\n",
        "    print(f\"Taxi Position: (row={taxi_row}, col={taxi_col})\")\n",
        "    print(f\"Passenger Location: {passenger_locations[passenger_location]}\")\n",
        "    print(f\"Destination: {destination_locations[destination]}\")\n",
        "\n",
        "print(\"\\nInitial State:\")\n",
        "describe_state(observation)\n",
        "\n",
        "# Define actions for Taxi-v3\n",
        "actions = {\n",
        "    0: \"Move South\",\n",
        "    1: \"Move North\",\n",
        "    2: \"Move East\",\n",
        "    3: \"Move West\",\n",
        "    4: \"Pick up passenger\",\n",
        "    5: \"Drop off passenger\"\n",
        "}\n",
        "for action_id in actions:\n",
        "    print(f\"Action {action_id}: {actions[action_id]}\")\n",
        "\n",
        "\n",
        "num_steps = 10  # Simulate a few steps\n",
        "print(\"\\nSimulating a few steps:\")\n",
        "for step in range(num_steps):\n",
        "    action = env.action_space.sample()  # Sample a random action\n",
        "\n",
        "    # Take a step in the environment\n",
        "    next_observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "    print(f\"\\nStep {step + 1}:\")\n",
        "    print(f\"Action taken: {actions[action]}\")\n",
        "    print(\"Next State (Observation):\")\n",
        "    describe_state(next_observation)\n",
        "    print(f\"Reward: {reward}\")\n",
        "    print(f\"Terminated: {terminated}\") # True if passenger is dropped off\n",
        "    print(f\"Truncated: {truncated}\") # True if max steps reached (default: 200)\n",
        "\n",
        "    if terminated or truncated:\n",
        "        print(\"Episode ended. Resetting environment.\")\n",
        "        observation, info = env.reset()  # Reset for a new episode\n",
        "        print(\"\\nNew Episode Started. Initial State:\")\n",
        "        describe_state(observation)\n",
        "\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PiNR24gblQ2",
        "outputId": "e9c577d9-c8f7-428b-e6be-6adf0fd4b0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(6)\n",
            "Observation Space: Discrete(500)\n",
            "\n",
            "Initial State:\n",
            "Observation (Encoded State): 268\n",
            "Taxi Position: (row=2, col=3)\n",
            "Passenger Location: Yellow (Y)\n",
            "Destination: Red (R)\n",
            "Action 0: Move South\n",
            "Action 1: Move North\n",
            "Action 2: Move East\n",
            "Action 3: Move West\n",
            "Action 4: Pick up passenger\n",
            "Action 5: Drop off passenger\n",
            "\n",
            "Simulating a few steps:\n",
            "\n",
            "Step 1:\n",
            "Action taken: Move East\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 288\n",
            "Taxi Position: (row=2, col=4)\n",
            "Passenger Location: Yellow (Y)\n",
            "Destination: Red (R)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 2:\n",
            "Action taken: Drop off passenger\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 288\n",
            "Taxi Position: (row=2, col=4)\n",
            "Passenger Location: Yellow (Y)\n",
            "Destination: Red (R)\n",
            "Reward: -10\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 3:\n",
            "Action taken: Drop off passenger\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 288\n",
            "Taxi Position: (row=2, col=4)\n",
            "Passenger Location: Yellow (Y)\n",
            "Destination: Red (R)\n",
            "Reward: -10\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 4:\n",
            "Action taken: Drop off passenger\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 288\n",
            "Taxi Position: (row=2, col=4)\n",
            "Passenger Location: Yellow (Y)\n",
            "Destination: Red (R)\n",
            "Reward: -10\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 5:\n",
            "Action taken: Move East\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 288\n",
            "Taxi Position: (row=2, col=4)\n",
            "Passenger Location: Yellow (Y)\n",
            "Destination: Red (R)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 6:\n",
            "Action taken: Move West\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 268\n",
            "Taxi Position: (row=2, col=3)\n",
            "Passenger Location: Yellow (Y)\n",
            "Destination: Red (R)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 7:\n",
            "Action taken: Drop off passenger\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 268\n",
            "Taxi Position: (row=2, col=3)\n",
            "Passenger Location: Yellow (Y)\n",
            "Destination: Red (R)\n",
            "Reward: -10\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 8:\n",
            "Action taken: Move South\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 368\n",
            "Taxi Position: (row=3, col=3)\n",
            "Passenger Location: Yellow (Y)\n",
            "Destination: Red (R)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 9:\n",
            "Action taken: Move East\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 388\n",
            "Taxi Position: (row=3, col=4)\n",
            "Passenger Location: Yellow (Y)\n",
            "Destination: Red (R)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "Truncated: False\n",
            "\n",
            "Step 10:\n",
            "Action taken: Pick up passenger\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 388\n",
            "Taxi Position: (row=3, col=4)\n",
            "Passenger Location: Yellow (Y)\n",
            "Destination: Red (R)\n",
            "Reward: -10\n",
            "Terminated: False\n",
            "Truncated: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "# Create the CliffWalking environment\n",
        "env = gym.make(\"CliffWalking-v1\")\n",
        "\n",
        "# Reset the environment and get the initial observation (state) and info\n",
        "observation, info = env.reset()\n",
        "\n",
        "print(\"Action Space:\", env.action_space)  # Discrete(4) - for 4 actions\n",
        "print(\"Observation Space:\", env.observation_space) # Discrete(48) - for 48 possible states\n",
        "\n",
        "\n",
        "def describe_state(observation, num_cols=12):\n",
        "    \"\"\"\n",
        "    Decodes the CliffWalking state (observation) into its row and column.\n",
        "    The observation is a single integer (0-47) representing the agent's position.\n",
        "    \"\"\"\n",
        "    if not isinstance(observation, int):\n",
        "        print(f\"Unexpected observation format in describe_state: Type - {type(observation)}, Value - {observation}\")\n",
        "        return\n",
        "\n",
        "    row = observation // num_cols\n",
        "    col = observation % num_cols\n",
        "\n",
        "    # Represent the grid for a clearer understanding\n",
        "    grid_representation = [\n",
        "        \"FFFFFFFFFFFF\",\n",
        "        \"FFFFFFFFFFFF\",\n",
        "        \"FFFFFFFFFFFF\",\n",
        "        \"SCCCCCCCCCCCG\"\n",
        "    ]\n",
        "    # Adjust for 0-indexed rows\n",
        "    grid_row = grid_representation[row]\n",
        "    cell_type = grid_row[col] if 0 <= col < len(grid_row) else \"Out of Bounds\"\n",
        "\n",
        "\n",
        "    print(f\"Observation (Encoded State): {observation}\")\n",
        "    print(f\"Agent Position: (row={row}, col={col})\")\n",
        "    print(f\"Cell Type: {cell_type} (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\")\n",
        "\n",
        "print(\"\\nInitial State:\")\n",
        "describe_state(observation)\n",
        "\n",
        "# Define actions for CliffWalking\n",
        "actions = {0: \"Up\", 1: \"Right\", 2: \"Down\", 3: \"Left\"}\n",
        "for action_id in actions:\n",
        "    print(f\"Action {action_id}: {actions[action_id]}\")\n",
        "\n",
        "\n",
        "num_steps = 15  # Simulate a few steps\n",
        "print(\"\\nSimulating a few steps:\")\n",
        "for step in range(num_steps):\n",
        "    action = env.action_space.sample()  # Sample a random action\n",
        "\n",
        "    # Take a step in the environment\n",
        "    # next_observation is the agent's new position\n",
        "    # reward is -1 (or -100 for cliff)\n",
        "    # terminated is True if goal reached\n",
        "    # truncated is False (no time limit by default)\n",
        "    next_observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "    print(f\"\\nStep {step + 1}:\")\n",
        "    print(f\"Action taken: {actions[action]}\")\n",
        "    print(\"Next State (Observation):\")\n",
        "    describe_state(next_observation)\n",
        "    print(f\"Reward: {reward}\")\n",
        "    print(f\"Terminated: {terminated}\")\n",
        "    # print(f\"Truncated: {truncated}\") # CliffWalking environment does not use truncation\n",
        "\n",
        "    if terminated:\n",
        "        print(\"Goal reached! Episode ended. Resetting environment.\")\n",
        "        observation, info = env.reset()\n",
        "        print(\"\\nNew Episode Started. Initial State:\")\n",
        "        describe_state(observation)\n",
        "\n",
        "\n",
        "env.close()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvqnYCCucr6N",
        "outputId": "27218bd9-1460-4add-ad44-8eba7995470c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(4)\n",
            "Observation Space: Discrete(48)\n",
            "\n",
            "Initial State:\n",
            "Observation (Encoded State): 36\n",
            "Agent Position: (row=3, col=0)\n",
            "Cell Type: S (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Action 0: Up\n",
            "Action 1: Right\n",
            "Action 2: Down\n",
            "Action 3: Left\n",
            "\n",
            "Simulating a few steps:\n",
            "\n",
            "Step 1:\n",
            "Action taken: Left\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 36\n",
            "Agent Position: (row=3, col=0)\n",
            "Cell Type: S (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 2:\n",
            "Action taken: Right\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 36\n",
            "Agent Position: (row=3, col=0)\n",
            "Cell Type: S (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -100\n",
            "Terminated: False\n",
            "\n",
            "Step 3:\n",
            "Action taken: Up\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 24\n",
            "Agent Position: (row=2, col=0)\n",
            "Cell Type: F (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 4:\n",
            "Action taken: Left\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 24\n",
            "Agent Position: (row=2, col=0)\n",
            "Cell Type: F (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 5:\n",
            "Action taken: Down\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 36\n",
            "Agent Position: (row=3, col=0)\n",
            "Cell Type: S (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 6:\n",
            "Action taken: Up\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 24\n",
            "Agent Position: (row=2, col=0)\n",
            "Cell Type: F (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 7:\n",
            "Action taken: Right\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 25\n",
            "Agent Position: (row=2, col=1)\n",
            "Cell Type: F (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 8:\n",
            "Action taken: Right\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 26\n",
            "Agent Position: (row=2, col=2)\n",
            "Cell Type: F (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 9:\n",
            "Action taken: Down\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 36\n",
            "Agent Position: (row=3, col=0)\n",
            "Cell Type: S (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -100\n",
            "Terminated: False\n",
            "\n",
            "Step 10:\n",
            "Action taken: Up\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 24\n",
            "Agent Position: (row=2, col=0)\n",
            "Cell Type: F (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 11:\n",
            "Action taken: Up\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 12\n",
            "Agent Position: (row=1, col=0)\n",
            "Cell Type: F (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 12:\n",
            "Action taken: Down\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 24\n",
            "Agent Position: (row=2, col=0)\n",
            "Cell Type: F (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 13:\n",
            "Action taken: Right\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 25\n",
            "Agent Position: (row=2, col=1)\n",
            "Cell Type: F (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 14:\n",
            "Action taken: Right\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 26\n",
            "Agent Position: (row=2, col=2)\n",
            "Cell Type: F (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n",
            "\n",
            "Step 15:\n",
            "Action taken: Right\n",
            "Next State (Observation):\n",
            "Observation (Encoded State): 27\n",
            "Agent Position: (row=2, col=3)\n",
            "Cell Type: F (S=Start, F=Frozen/Safe, C=Cliff, G=Goal)\n",
            "Reward: -1\n",
            "Terminated: False\n"
          ]
        }
      ]
    }
  ]
}